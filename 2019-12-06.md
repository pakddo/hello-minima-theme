---
layout: post
title: "데이터 파이프 라인 구축"
---
## 개요
 - AWS2NCP 이관을 위하여...
 - 일반적인 로그 분석 시스템
  ![general](https://t1.daumcdn.net/cfile/tistory/2510314D5886F3942F)
    - 출처 : 조대협의 블로그 (https://bcho.tistory.com/1158)

  - Action-Items
    - As-Is / To-Be 상황 정리
    - 진행 단계
      1. 로그 수집 방식 결정
      2. 기존 데이터 이관
        - s3 -> object storage
        - hive 만 먼저
        - 로그데이터는 이관할지 신규 데이터로만 적재할지 결정 필요
      3. 배치클러스터 설정
        - 현재 시스템에서 설치해야하는 소프트웨어 리스트 업
        - 1차 구성
          - HDP
          - hive / presto / airflow
      4. 분석클러스터 설정

----

## As-Is / To-Be 상황 정리
  ### As-Is
  - 구성

    항목 | 구성 기술
    --|--
    API 서버 | Ruby On Rails
    Message Q | Log-stash, AWS Kinesis Stream
    Message Consumer | AWS Kinesis Stream
    Log Storage | AWS S3
    Hive Engine | Apache Presto
    Reporting | Tableau

  - 문제점
    - 로그 수집시 log-stash 다운이 잦음
    - 배치 형태의 로그 수집 api-log / event-log
    - 임시 hive 테이블 생성이 어려움
  - 해결방안
    - 실시간 처리 도입 (spark-kafka)
    - hive 권한관리 /w presto

  ### To-Be
  - 구성

    항목 | 구성 기술
    --|--
    API 서버 | Ruby On Rails
    Message Q | Kafka Stream Producer
    Message Consumer | Kafka Consumer
    Log Storage | NCP Object Storage
    Hive Engine | Apache Presto
    Reporting | Tableau

----

## 진행단계별 실행 Log
  0. 로그 수집 방식 결정
    - 로그 수집 방식 변경은 프로덕트 개발 부분과 밀접한 연관이 있으므로 따로 수정하지 않는 것으로 함
    - 현재 구성
      - API LOG
        - ELK 스택 중 elasticSearch + logStash 부분의 연동이 비정상동작
        - 2020년 상반기 중 서버/웹팀 주도로 유지보수 예정
      - EVENT LOG
        - Kinesis + Firehose + API gateway 구성
        - 정상 동작

----

  1. 기존 데이터 이관
    - rclone sync 기능을 활용하기로 결정
      - 다양한 cloud storage 지원
      - CLI 지원
      - 빠른 속도
    - AWS S3 <-> NCP Object Storage 데이터 동기화
      - hive 데이터 이관
        - 12/26 시점 데이터 약 830GB를 전체 복제 완료
        - AWS EC2 인스턴스에서 전송
      - 데이터 동기화
        - 전송 대상 데이터에 개인정보가 포함되어 있어 보안 네트워크(ex. IPSEC) 구성 필요
          - NCP 인스턴스에서 IPSEC VPN 을 경유하여 동기화 할 수 있도록 구성 테스트
          - 구성 방식에 대한 리서치 및 PoC 수행
        - 보안 네트워크 구성 완료
          - 구조상 IPSEC 구성이 어려움으로 다른 방식의 보안 네트워크를 구성함
          - proxy + https 활용
        - 로그 데이터 대상으로 2020년 1월 1일 이후 데이터 동기화            
          - log 데이터 (api/event) 대상 동기화 작업
            - rclone + crontab 활용    
            - 동기화 주기 및 데이터 사이즈 (재확인 필요)
              - event_log : 동기화 주기 1시간
                - 크기 : 시간당 약 150MB
              - api_log : 동기화 주기 1일
                - 크기 : 일당 3.6GB

        ​
  2. 배치 클러스터 구축
    - NCP 서버 인스턴스 3대 기준으로 초기 구축 진행
      - HDP 설치 진행 완료 (HDFS, HIVE, SPARK)
        - HDP 3.1 설치 완료 (인스턴스 3대 구성)
        - HDFS / Sqoop / Spark / Hive
      - 필요 솔루션 추가 구성 진행 예정 (Presto, Airflow)
        - 기존 배치 작업을 많은 수정없이 옮길 수 있도록 추가 솔루션 설치 필요
          1. Presto / Hive Query Engine
          2. Airflow / Batch Scheduler
      - Hive 메타 스토어 재구성
        - Object Storage 에 저장된 Parquet 데이터 기준으로 hive meta-store 재구성
    - 배치 작업 이관
      - 로그 데이터 동기화 작업 및 Hive 메타 스토어 재구성 이후 진행  
​
  3. 분석 클러스터 구축 (~3월)
   - 클라우드 하둡 서비스 활용
   - 설치형 Presto를 Managed Service로 대체 가능할지 확인 필요
