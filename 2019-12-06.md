---
layout: post
title: "데이터 파이프 라인 구축"
---
## 개요
 - AWS2NCP 이관을 위하여...
 - 일반적인 로그 분석 시스템
  ![general](https://t1.daumcdn.net/cfile/tistory/2510314D5886F3942F)
    - 출처 : 조대협의 블로그 (https://bcho.tistory.com/1158)

  - Action-Items
    - As-Is / To-Be 상황 정리
    - 진행 단계
      1. 로그 수집 방식 결정
      2. 기존 데이터 이관
        - s3 -> object storage
        - hive 만 먼저
        - 로그데이터는 이관할지 신규 데이터로만 적재할지 결정 필요
      3. 배치클러스터 설정
        - 현재 시스템에서 설치해야하는 소프트웨어 리스트 업
        - 1차 구성
          - HDP
          - hive / presto / airflow
      4. 분석클러스터 설정

----

## As-Is / To-Be 상황 정리
  ### As-Is
  - 구성

    항목 | 구성 기술
    --|--
    API 서버 | Ruby On Rails
    Message Q | Log-stash, AWS Kinesis Stream
    Message Consumer | AWS Kinesis Stream
    Log Storage | AWS S3
    Hive Engine | Apache Presto
    Reporting | Tableau

  - 문제점
    - 로그 수집시 log-stash 다운이 잦음
    - 배치 형태의 로그 수집 api-log / event-log
    - 임시 hive 테이블 생성이 어려움
  - 해결방안
    - 실시간 처리 도입 (spark-kafka)
    - hive 권한관리 /w presto

  ### To-Be
  - 구성
    항목 | 구성 기술
    --|--
    API 서버 | Ruby On Rails
    Message Q | Kafka Stream Producer
    Message Consumer | Kafka Consumer
    Log Storage | NCP Object Storage
    Hive Engine | Apache Presto
    Reporting | Tableau

----

## 진행단계별 실행 Log
  1. 로그 수집 방식 결정
    - 로그 수집 방식 변경은 프로덕트 개발 부분과 밀접한 연관이 있으므로 따로 수정하지 않는 것으로 함
  2. 기존 데이터 이관
    - rclone sync 기능을 활용하기로 결정
    - IPSEC 적용 필요 여부를 검토
      - 최초 동기화 시 미적용
        - 동기화 시점의 hive 데이터 (12/26 예상)
      - 이후 데이터 업데이트 작업에 IPSEC을 필수적으로 반영하기로 함 (개인정보 유출 가능성 때문)
        - bind 옵션을 통해 특정 network interface를 사용하는 방식으로 가능
        - 구성 방식에 대한 리서치 필요
  3. 배치 클러스터 설정
    - HDP 3.1 설치 완료 (인스턴스 3대 구성)
      - HDFS / Sqoop / Spark / Hive
    - 추가 설치 필요 솔루션
      - airflow / presto
      - 대체 가능 여부 검토가 필요한가..?
        - Why? 
        - Why NOT?



